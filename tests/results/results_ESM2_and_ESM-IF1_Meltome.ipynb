{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6f032",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import __init__\n",
    "from src.utilities import train_test_validation_splits, \\\n",
    "                            prepare_train_test_val_seqs_by_batches, \\\n",
    "                            tensor2dataloader, load_full_meltome_FLIP_db, \\\n",
    "                            seek_UniprotID_association_Meltome_prots,\\\n",
    "                            download_UniprotID_Alphafold_Structures,\\\n",
    "                            get_guided_encoder_output,\\\n",
    "                            ESM2_IF_repr\n",
    "                            \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "path_meltome = '../datasets/FLIP/splits/meltome/splits/mixed_split.csv'\n",
    "complete_meltome_db = '../datasets/FLIP/splits/meltome/full_dataset_sequences.fasta'\n",
    "\n",
    "full_meltome_db = load_full_meltome_FLIP_db(complete_meltome_db)\n",
    "\n",
    "splits_meltome = pd.read_csv(path_meltome, sep=',')\n",
    "split_meltome = splits_meltome[splits_meltome['sequence'].str.len()>= 50]\n",
    "train, val, test = train_test_validation_splits(splits_meltome)\n",
    "train = seek_UniprotID_association_Meltome_prots(train, full_meltome_db)\n",
    "test = seek_UniprotID_association_Meltome_prots(test, full_meltome_db)\n",
    "val = seek_UniprotID_association_Meltome_prots(val, full_meltome_db)\n",
    "#print(train)\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "#ff=full_meltome_db[full_meltome_db['sequence'].isin(train['sequence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183d326",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from src.ESM2embeddings import ESM2embeddings\n",
    "from src.ESM2_IF1_embeddings import ESM2_IF1_embeddings\n",
    "from src.utilities import train_test_validation_splits, prepare_train_test_val_seqs_by_batches, tensor2dataloader\n",
    "from src.NeuralArchitectures import regressionHead\n",
    "from src.Trainer import Trainer\n",
    "\n",
    "structuredir = '../datasets/Structures/'\n",
    "meltome_struct_dir_labels = '../datasets/'\n",
    "\n",
    "\n",
    "import os \n",
    "if not os.listdir(structuredir) and not os.path.isfile(meltome_struct_dir_labels+'Meltome_Splits_FLIPS_train.txt')\\\n",
    "                                and not os.path.isfile(meltome_struct_dir_labels+'Meltome_Splits_FLIPS_test.txt')\\\n",
    "                                and not os.path.isfile(meltome_struct_dir_labels+'Meltome_Splits_FLIPS_val.txt'): \n",
    "    \n",
    "    print(\"Finding structures to proteins via Alphafold/PDB dbs..........\") \n",
    "    \n",
    "    download_UniprotID_Alphafold_Structures(train, structuredir, meltome_struct_dir_labels, 'Meltome_Splits_FLIPS_train')\n",
    "    download_UniprotID_Alphafold_Structures(test, structuredir, meltome_struct_dir_labels, 'Meltome_Splits_FLIPS_test')\n",
    "    download_UniprotID_Alphafold_Structures(val, structuredir, meltome_struct_dir_labels, 'Meltome_Splits_FLIPS_val')\n",
    "\n",
    "\n",
    "\n",
    "Structinfo_Meltome_Splits_train = pd.read_csv( meltome_struct_dir_labels+'Meltome_Splits_FLIPS_train.txt', sep='\\t')\n",
    "Structinfo_Meltome_Splits_test = pd.read_csv( meltome_struct_dir_labels+'Meltome_Splits_FLIPS_test.txt', sep='\\t')\n",
    "Structinfo_Meltome_Splits_val = pd.read_csv( meltome_struct_dir_labels+'Meltome_Splits_FLIPS_val.txt', sep='\\t')\n",
    "\n",
    "\n",
    "train = pd.concat([train, Structinfo_Meltome_Splits_train], axis=1).query('Source==\"alphafold\"')\n",
    "test = pd.concat([test, Structinfo_Meltome_Splits_test], axis=1).query('Source==\"alphafold\"')\n",
    "val = pd.concat([val, Structinfo_Meltome_Splits_val], axis=1).query('Source==\"alphafold\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7a4c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch, os, gc\n",
    "import torch_geometric\n",
    "import torch_sparse\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\"\"\"import esm\n",
    "model, alphabet = esm.pretrained.load_model_and_alphabet_local(\"../models/esm_if1_gvp4_t16_142M_UR50.pt\")#esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
    "model = model.eval()\"\"\"\n",
    "\n",
    "IF1 = ESM2_IF1_embeddings()\n",
    "\n",
    "\n",
    "pt_batch_size = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ESM2 = ESM2embeddings(type_embedding = \"facebook/esm2_t33_650M_UR50D\", device = device, type_tool='FacebookESM2')\n",
    "\n",
    "dir_pre_generated_embeddings = '../prepro_embeddings/'\n",
    "\n",
    "path_train= dir_pre_generated_embeddings+'train_set_embeddings_ESM2_with_StructAssociation.pth'\n",
    "path_test= dir_pre_generated_embeddings+'test_set_embeddings_ESM2_with_StructAssociation.pth'\n",
    "path_val= dir_pre_generated_embeddings+'val_set_embeddings_ESM2_with_StructAssociation.pth'\n",
    "\n",
    "path_IFtrain= dir_pre_generated_embeddings+'train_set_IFembeddings_ESM2_StructAssociation.pth'\n",
    "path_IFtest= dir_pre_generated_embeddings+'test_set_IFembeddings_ESM2_StructAssociation.pth'\n",
    "path_IFval= dir_pre_generated_embeddings+'val_set_IFembeddings_ESM2_StructAssociation.pth'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def embedding_builder_ESM2(ESM2, device, train, test, val, path_train, path_test, path_val):\n",
    "    if os.path.isfile(path_train)==False and os.path.isfile(path_test)==False and os.path.isfile(path_val)==False:\n",
    "\n",
    "        print (\"Creating Embeddings...\")   \n",
    "        train_embeddings = ESM2.esm2embedding(train, device, layer_index=33) #esm2embedding(train, model, batch_converter, device, layer_index=33)#BERT.embed_dataset(batch_train)\n",
    "        torch.save(train_embeddings, path_train)\n",
    "        test_embeddings = ESM2.esm2embedding(test, device, layer_index=33) #esm2embedding(test, model, batch_converter, device, layer_index=33)\n",
    "        torch.save(test_embeddings, path_test)\n",
    "        val_embeddings = ESM2.esm2embedding(val, device, layer_index=33) #esm2embedding(val, model, batch_converter, device, layer_index=33)\n",
    "        torch.save(val_embeddings, path_val)\n",
    "        print (\"Loaded\")\n",
    "    else:\n",
    "        print (\"Loading Premade Embeddings...\")\n",
    "        train_embeddings = torch.load(path_train)\n",
    "        test_embeddings = torch.load(path_test)\n",
    "        val_embeddings = torch.load(path_val)\n",
    "        print (\"Loaded\")\n",
    "    return train_embeddings, test_embeddings, val_embeddings\n",
    "\n",
    "\n",
    "#def IFBuilder_sets(model, alphabet, train, test, val, path_IFtrain, path_IFtest, path_IFval):\n",
    "def IFBuilder_sets(IF, train, test, val, path_IFtrain, path_IFtest, path_IFval):\n",
    "\n",
    "    if os.path.isfile(path_IFtrain)==False and os.path.isfile(path_IFtest)==False and os.path.isfile(path_IFval)==False:\n",
    "\n",
    "        #IF_embeddings_train = ESM2_IF_repr(train, model, alphabet, folder_path='../prepro_embeddings/esm2_if1_embeddings/Meltome_train')\n",
    "        IF_embeddings_train = IF.ESM2_IF_repr(train, folder_path='../prepro_embeddings/esm2_if1_embeddings/Meltome_train')\n",
    "        torch.save(IF_embeddings_train, path_IFtrain)\n",
    "\n",
    "        #IF_embeddings_test = ESM2_IF_repr(test, model, alphabet, folder_path='../prepro_embeddings/esm2_if1_embeddings/Meltome_test')\n",
    "        IF_embeddings_test = IF.ESM2_IF_repr(test, folder_path='../prepro_embeddings/esm2_if1_embeddings/Meltome_test')\n",
    "        torch.save(IF_embeddings_test, path_IFtest)\n",
    "\n",
    "        #IF_embeddings_val = ESM2_IF_repr(val, model, alphabet, folder_path='../prepro_embeddings/esm2_if1_embeddings/Meltome_val')\n",
    "        IF_embeddings_val = IF.ESM2_IF_repr(val, folder_path='../prepro_embeddings/esm2_if1_embeddings/Meltome_val')\n",
    "        torch.save(IF_embeddings_val, path_IFval)\n",
    "    else:\n",
    "        print (\"Loading Premade Embeddings...\")\n",
    "        train_embeddings = torch.load(path_IFtrain)\n",
    "        test_embeddings = torch.load(path_IFtest)\n",
    "        val_embeddings = torch.load(path_IFval)\n",
    "        print (\"Loaded\")\n",
    "    return train_embeddings, test_embeddings, val_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba273f5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_IF_embedding, test_IF_embedding, val_IF_embedding = IFBuilder_sets(IF1, train, test, val, path_IFtrain, path_IFtest, path_IFval)\n",
    "train_embeddings, test_embeddings, val_embeddings = embedding_builder_ESM2(ESM2, device, train, test, val,  path_train, path_test, path_val)\n",
    "\n",
    "train_loaderESM2 = tensor2dataloader(train_embeddings, torch.from_numpy( train.target.to_numpy().astype(float) ), batch_size=50)\n",
    "test_loaderESM2 = tensor2dataloader(test_embeddings, torch.from_numpy( test.target.to_numpy().astype(float) ), batch_size=50)\n",
    "val_loaderESM2 = tensor2dataloader(val_embeddings, torch.from_numpy( val.target.to_numpy().astype(float) ), batch_size=50)\n",
    "\n",
    "train_loaderIF = tensor2dataloader(train_IF_embedding, torch.from_numpy( train.target.to_numpy().astype(float) ), batch_size=50)\n",
    "test_loaderIF = tensor2dataloader(test_IF_embedding, torch.from_numpy( test.target.to_numpy().astype(float) ), batch_size=50)\n",
    "val_loaderIF = tensor2dataloader(val_IF_embedding, torch.from_numpy( val.target.to_numpy().astype(float) ), batch_size=50)\n",
    "\n",
    "train_loaderMixed = tensor2dataloader(torch.concat([train_embeddings.to(device), train_IF_embedding.to(device)],dim=1), torch.from_numpy( train.target.to_numpy().astype(float) ), batch_size=50)\n",
    "test_loaderMixed = tensor2dataloader(torch.concat([test_embeddings.to(device), test_IF_embedding.to(device)],dim=1), torch.from_numpy( test.target.to_numpy().astype(float) ), batch_size=50)\n",
    "val_loaderMixed = tensor2dataloader(torch.concat([val_embeddings.to(device), val_IF_embedding.to(device)],dim=1), torch.from_numpy( val.target.to_numpy().astype(float) ), batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ab699",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generating_results_approaches(FFNNreg, Trner, train_loader, val_loader, test_loader,loss, opt, epochs, device):\n",
    "    FFNNreg, val_loss = Trner.train_LLMRegresor(train_loader, val_loader, FFNNreg, device, loss, opt, epochs)\n",
    "\n",
    "    test_set, test_labels = test_loader.dataset.tensors\n",
    "    loss_test, outcome = Trner.test_model(FFNNreg, test_set, test_labels, loss, device)\n",
    "\n",
    "    from src.utilities import plot_results\n",
    "\n",
    "    plot_results( outcome, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eda2059c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### For RAW ESM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018a5bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Trainer1 = Trainer()\n",
    "FFNN_ESM2 = regressionHead(train_embeddings.shape[1::])\n",
    "optESM2 = torch.optim.Adam(FFNN_ESM2.parameters(), lr=1e-4)\n",
    "lossESM2= torch.nn.MSELoss()\n",
    "epochs = 200\n",
    "\n",
    "generating_results_approaches(FFNN_ESM2, Trainer1, train_loaderESM2, val_loaderESM2, test_loaderESM2,lossESM2, optESM2, epochs, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8629c9c8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### For Inverse Folding ESM2 Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d316997",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Trainer2 = Trainer()\n",
    "FFNN_IF = regressionHead(train_IF_embedding.shape[1::] )\n",
    "optIF = torch.optim.Adam(FFNN_IF.parameters(), lr=1e-4)\n",
    "lossIF= torch.nn.MSELoss()\n",
    "epochs = 200\n",
    "\n",
    "generating_results_approaches(FFNN_IF, Trainer2, train_loaderIF, val_loaderIF, test_loaderIF,lossIF, optIF, epochs, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8aa0395f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Combining Raw ESM2 and Inverse Folding Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f2030",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Trainer3 = Trainer()\n",
    "FFNN_Mixed = regressionHead(train_IF_embedding.size(1) + train_embeddings.size(1))\n",
    "optMixed = torch.optim.Adam(FFNN_Mixed.parameters(), lr=1e-4)\n",
    "lossMixed= torch.nn.MSELoss()\n",
    "epochs = 200\n",
    "\n",
    "generating_results_approaches(FFNN_Mixed, Trainer3, train_loaderMixed, val_loaderMixed, test_loaderMixed,lossMixed, optMixed, epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermoPML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 403.253626,
   "end_time": "2023-05-30T15:43:47.817884",
   "environment_variables": {},
   "exception": null,
   "input_path": "ESM2_and_ESM-IF1.ipynb",
   "output_path": "results/results_ESM2_and_ESM-IF1_Meltome.ipynb",
   "parameters": {},
   "start_time": "2023-05-30T15:37:04.564258",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}