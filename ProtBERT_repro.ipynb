{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "tmpfiles = '/content/tmp/'\n",
        "train_tmp_folder = tmpfiles+'train_embeddinds/'\n",
        "test_tmp_folder = tmpfiles+'test_embeddinds/'\n",
        "val_tmp_folder = tmpfiles+'val_embeddinds/'\n",
        "\n",
        "import os.path\n",
        "from os import path\n",
        "\n",
        "if path.exists(tmpfiles) == False:\n",
        "\n",
        "  os.mkdir(tmpfiles)\n",
        "  os.mkdir(train_tmp_folder )\n",
        "  os.mkdir(test_tmp_folder )\n",
        "  os.mkdir(val_tmp_folder )\n",
        "else:\n",
        "  if path.exists(train_tmp_folder) == False or path.exists(test_tmp_folder) == False or path.exists(val_tmp_folder) == False:\n",
        "    try:\n",
        "      os.mkdir(train_tmp_folder )\n",
        "      os.mkdir(test_tmp_folder )\n",
        "      os.mkdir(val_tmp_folder )\n",
        "    except Exception:\n",
        "      pass\n",
        "\n",
        "!ls\n",
        "\n",
        "#%cd /content/gdrive/MyDrive/ThermostabilityProject/\n",
        "!pip install transformers tqdm\n",
        "%cd /content/gdrive/MyDrive/ThermostabilityProject/\n"
      ],
      "metadata": {
        "id": "RxcVgWfT4rK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4000ecb-af31-4832-b70c-67db642ac38f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "gdrive\tsample_data  tmp\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "/content/gdrive/MyDrive/ThermostabilityProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-1FI9QjKlF7",
        "outputId": "965904df-f66a-481c-ab9c-8479628d8302"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets\t\t\t\t prepro_embeddings     ref_models\n",
            "drive-download-20230426T195016Z-001.zip  ProtBERT_repro.ipynb  train_tmp_folder\n",
            "filename_pi.pth\t\t\t\t README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bettertransformers optimum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HJNXNMKBTgW",
        "outputId": "46175df2-bee3-4ce6-9b50-cd5498434b34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bettertransformers in /usr/local/lib/python3.10/dist-packages (4.23.0.dev0)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (1.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from bettertransformers) (0.12.1)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (4.28.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.11.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from optimum) (0.15.1+cu118)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.0.0+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (2.12.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->bettertransformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->bettertransformers) (2023.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum) (16.0.2)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum) (3.20.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (1.5.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.8.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (9.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bettertransformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->bettertransformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bettertransformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bettertransformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->optimum) (8.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.9.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum) (2.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bBvNg9-S5eNV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch, torch.nn\n",
        "from transformers import BertModel, BertTokenizer, pipeline\n",
        "import re, gc, os\n",
        "import requests\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9PMfsMzb5eNZ"
      },
      "outputs": [],
      "source": [
        "def train_test_validation_splits(df):\n",
        "    test,train_tot = df.loc[df['set']=='test'],df.loc[df['set']=='train']\n",
        "    train, val = train_tot.loc[train_tot['validation']!=True], train_tot.loc[train_tot['validation']==True]\n",
        "    return train,val, test\n",
        "\n",
        "def build_batch_iterator_sequences(sequences_total, batch_size):\n",
        "\n",
        "    long_list = sequences_total\n",
        "    sub_list_length = batch_size\n",
        "    sub_lists = [\n",
        "        long_list[i : i + sub_list_length]\n",
        "        for i in range(0, len(long_list), sub_list_length)\n",
        "    ]\n",
        "    return sub_lists\n",
        "\n",
        "def get_features_from_embeddings(embeddings, attention_mask):\n",
        "    features = [] \n",
        "    for seq_num in range(len(embeddings)):\n",
        "          seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "          seq_emd = embeddings[seq_num][1:seq_len-1]\n",
        "          features.append(seq_emd)\n",
        "\n",
        "def embed_dataset(dataset_seqs, model, tokenizer, device, path, shift_left = 1, shift_right = -1):\n",
        "  inputs_embedding = []\n",
        "\n",
        "  cont=0\n",
        "  \n",
        "  for sample in tqdm(dataset_seqs):\n",
        "    with torch.no_grad():\n",
        "      ''' As we are using it in unsupervised manner, we are ignoring the CLS token and so, what's why \n",
        "          we are ignoring the special tokens (inspect better in huggingface why the three values in the output)'''\n",
        "      #ids = tokenizer.batch_encode_plus(sample, add_special_tokens=True, padding=True, is_split_into_words=True, return_tensors=\"pt\")      \n",
        "      #ids = tokenizer.batch_encode_plus(sample, add_special_tokens=False, padding=True, is_split_into_words=True, return_tensors=\"pt\")\n",
        "      #embedding = model(input_ids=ids['input_ids'].to(device))[0]\n",
        "      #inputs_embedding.append(embedding.detach().cpu().numpy())\n",
        "      \n",
        "      #ids = tokenizer.encode_plus(list(sample.strip()), add_special_tokens=True, padding=True, \n",
        "      #                                                         return_attention_mask = True, return_tensors=\"pt\")\n",
        "      #embedding = model(input_ids=ids['input_ids'].reshape(-1,1).to(device), attention_mask = ids['attention_mask'].reshape(-1,1).to(device))[0]\n",
        "      #np.savez(path + str(cont)+'.npz',  embedding.detach().cpu().numpy() )\n",
        "      #cont+=1\n",
        "  \n",
        "\n",
        "\n",
        "      ''' Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)'''\n",
        "      #import pdb; pdb.set_trace()\n",
        "      sequences_Example = sample #[\"A E T C Z A O\",\"S K T Z P\"]\n",
        "\n",
        "      sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]\n",
        "\n",
        "      '''. Tokenize, encode sequences and load it into the GPU if possibile'''\n",
        "\n",
        "      ids = tokenizer.batch_encode_plus(sequences_Example, add_special_tokens=True, padding=True)\n",
        "\n",
        "      input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "      attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "      ''' Extracting sequences' features and load it into the CPU if needed'''\n",
        "\n",
        "      with torch.no_grad():\n",
        "          embedding = model(input_ids=input_ids,attention_mask=attention_mask)[0]\n",
        "\n",
        "      #import pdb; pdb.set_trace()\n",
        "      embedding = embedding.detach().cpu().numpy()\n",
        "\n",
        "      #embedding = get_features_from_embeddings(embedding)\n",
        "\n",
        "\n",
        "      np.savez(path + str(cont)+'.npz',  embedding )\n",
        "      cont+=1\n",
        "\n",
        "      del ids, embedding\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "  return inputs_embedding\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F9Qo57a5eNa",
        "outputId": "802a0425-170b-4fe1-cdb0-259ca2bb93a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "path_meltome = 'datasets/FLIP/splits/meltome/splits/mixed_split.csv'\n",
        "\n",
        "splits_meltome = pd.read_csv(path_meltome, sep=',')\n",
        "split_meltome = splits_meltome[splits_meltome['sequence'].str.len()>= 50]\n",
        "splits_meltome['sequence']=splits_meltome['sequence'].str.join(\" \")\n",
        "train, val, test = train_test_validation_splits(splits_meltome)\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uDg6RdMqGlUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits_meltome['sequence'].to_list())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rR4H8wZyl0B",
        "outputId": "b790787b-7fbc-451d-9b44-7d40e39f3d39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27951"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCT9azGEIDdB",
        "outputId": "470d8cd3-80dd-41a8-e277-0ee2bc68d2e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.38.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ltFG8m5eNb",
        "outputId": "577e339d-e3f7-47aa-edba-13c011ea8ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "#from accelerate import init_empty_weights\n",
        "#from accelerate import infer_auto_device_map\n",
        "max_memory_mapping = {0: \"7GB\", 'cpu': \"8GB\"}\n",
        "from optimum.bettertransformer import BetterTransformer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
        "model = BertModel.from_pretrained(\"Rostlab/prot_bert\", low_cpu_mem_usage=True, max_memory=max_memory_mapping)\n",
        "model = BetterTransformer.transform(model, keep_original_model=True)\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = model.to(device=device)\n",
        "model = model.eval()\n",
        "if torch.cuda.is_available():\n",
        "  model = model.half()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pooling_and_final_representation(path):\n",
        "  # Due to npz compression on each embedded sequence\n",
        "  #import pdb; pdb.set_trace()\n",
        "  sample = np.load(path)\n",
        "  embedded_seq = torch.from_numpy( sample[sample.files[0]] ).to(torch.float32)\n",
        "  #embedded_seq = embedded_seq.view(embedded_seq.size(0), -1).permute(1,0)\n",
        "  embedded_seq = embedded_seq.permute(0,2,1)\n",
        "  GlobalAvgpooling = torch.nn.AvgPool1d(kernel_size = embedded_seq.size(2) , stride = 1, padding = 0)\n",
        "  pooled_seq = GlobalAvgpooling(embedded_seq)\n",
        "\n",
        "  return pooled_seq #pooled_seq.permute(1,0)\n",
        "\n",
        "#the test\n",
        "\n",
        "def pooled_set_of_sequences(folder_path):\n",
        "  #import pdb; pdb.set_trace()\n",
        "  list_embeddings = []\n",
        "  iter_paths = os.listdir(folder_path)\n",
        "  for path in tqdm(iter_paths):\n",
        "    list_embeddings.append( pooling_and_final_representation(folder_path + path) )\n",
        "\n",
        "  #import pdb;pdb.set_trace()\n",
        "  representation = torch.stack(list_embeddings)\n",
        "  representation = representation.view(representation.size(0),-1)\n",
        "  return representation\n",
        "\n",
        "#train_embeddings = pooled_set_of_sequences(train_tmp_folder)\n",
        "#test_embeddings = pooled_set_of_sequences(test_tmp_folder)\n",
        "#val_embeddings = pooled_set_of_sequences(val_tmp_folder)"
      ],
      "metadata": {
        "id": "tAnURLQbNxqN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-zm1vGvxwEb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "7b87ecdd70764b2f9a2d21230926b863",
            "faa5eba9598e4a90b7f261b10bcfe847",
            "c3c929b7eef9456a842197f4c0f64c02",
            "45ffb5134b264edebce27e6f1fb935ab",
            "615fdcd32f98425fae864e9fb800bd81",
            "373dfbeeed6f47c5aec62023234e5a71",
            "2dcd698c77a94eb39f8b130661295d86",
            "657188850552479d87728d479780697f",
            "cac6f51421ff420a9d8ddf87d065a470",
            "19c3aa9a55524159b829e288e3da74ee",
            "393355f492bf421fa447a10ca09635d1"
          ]
        },
        "outputId": "5f99bcda-614b-4d19-f62a-0abe89786412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22335 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b87ecdd70764b2f9a2d21230926b863"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/optimum/bettertransformer/models/encoder_models.py:247: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
            "  hidden_states = torch._nested_tensor_from_mask(hidden_states, ~attention_mask)\n"
          ]
        }
      ],
      "source": [
        "dir_pre_generated_embeddings = ''\n",
        "path_train= dir_pre_generated_embeddings+'train_set_embeddings.pth'\n",
        "path_test= dir_pre_generated_embeddings+'test_set_embeddings.pth'\n",
        "path_val= dir_pre_generated_embeddings+'val_set_embeddings.pth'\n",
        "\n",
        "\n",
        "if os.path.isfile(path_train)==False and os.path.isfile(path_test)==False and os.path.isfile(path_val)==False:\n",
        "    #if path.exists(train_tmp_folder) == False or path.exists(test_tmp_folder) == False or path.exists(val_tmp_folder) == False:\n",
        "    batch_size = 1\n",
        "    batch_train = build_batch_iterator_sequences(train.sequence.to_list(), batch_size)\n",
        "    batch_test = build_batch_iterator_sequences(test.sequence.to_list(), batch_size)\n",
        "    batch_val = build_batch_iterator_sequences(val.sequence.to_list(), batch_size)\n",
        "    \n",
        "    \n",
        "    print (\"Creating Embeddings...\")\n",
        "    embed_dataset(batch_train, model, tokenizer, device, train_tmp_folder)\n",
        "    embed_dataset(batch_test, model, tokenizer, device, test_tmp_folder)\n",
        "    embed_dataset(batch_val, model, tokenizer, device, val_tmp_folder)\n",
        "    print (\"DONE!!...\")\n",
        "\n",
        "    print (\"Loading Premade Embeddings...\")\n",
        "\n",
        "    train_embeddings = pooled_set_of_sequences(train_tmp_folder)\n",
        "    torch.save(train_embeddings, 'train_set_embeddings.pth')\n",
        "    test_embeddings = pooled_set_of_sequences(test_tmp_folder)\n",
        "    torch.save(test_embeddings, 'test_set_embeddings.pth')\n",
        "    val_embeddings = pooled_set_of_sequences(val_tmp_folder)\n",
        "    torch.save(val_embeddings, 'val_set_embeddings.pth')\n",
        "    print (\"Loaded\")\n",
        "else:\n",
        "    print (\"Loading Premade Embeddings...\")\n",
        "    train_embeddings = torch.load('train_set_embeddings.pth')\n",
        "    test_embeddings = torch.load('test_set_embeddings.pth')\n",
        "    val_embeddings = torch.load('val_set_embeddings.pth')\n",
        "    print (\"Loaded\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 /content/tmp"
      ],
      "metadata": {
        "id": "ltTKZbRGr0cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1s-VG_FMmlh"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data_utils\n",
        "\n",
        "batch_size=50\n",
        "\n",
        "\n",
        "trainDataset = data_utils.TensorDataset(train_embeddings, torch.from_numpy( train.target.to_numpy() ))\n",
        "testDataset = data_utils.TensorDataset(test_embeddings, torch.from_numpy( test.target.to_numpy() ))\n",
        "valDataset = data_utils.TensorDataset(val_embeddings, torch.from_numpy( val.target.to_numpy() ))\n",
        "\n",
        "train_loader = data_utils.DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = data_utils.DataLoader(testDataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = data_utils.DataLoader(valDataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmQ0v7Cv5eNc"
      },
      "outputs": [],
      "source": [
        "class Flatten(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)   \n",
        "\n",
        "class regressionHead(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, kernel):\n",
        "        super(regressionHead, self).__init__()\n",
        "        #self.input_shape = input_shape # pos0 = #channels, pos1 = #diagonal comps, or viseversa\n",
        "\n",
        "\n",
        "        self.FFNN = torch.nn.Sequential(\n",
        "            Flatten(),\n",
        "            torch.nn.Linear(1024, 512),\n",
        "            torch.nn.ReLU(), #nn.ReLU(),\n",
        "            torch.nn.Linear(512, 512),\n",
        "            torch.nn.ReLU(), #nn.ReLU(),\n",
        "            torch.nn.Linear(512, 1),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        #self.encoder.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.kaiming_normal_(module.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.pooling(x).mean(dim=0)\n",
        "        z = self.FFNN(x)\n",
        "        return z #z.permute(0,2,1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "todfNCMDdn49"
      },
      "outputs": [],
      "source": [
        "def train_LLMRegresor(train_iterator, val_iterator, model, device, criterion, optimizer, epoch_num):\n",
        "    \n",
        "        \n",
        "        val_loss = []\n",
        "        \n",
        "        model.to(device)\n",
        "\n",
        "        for epoch in range(epoch_num):\n",
        "            model.train() \n",
        "            for i, (input, label) in enumerate(train_iterator):\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                input = input.to(dtype=torch.float32, device=device)\n",
        "                label = label.to(dtype=torch.float32, device=device) \n",
        "                out = model(input)\n",
        "                loss = criterion(out, label.unsqueeze(-1))\n",
        "                loss.backward() \n",
        "                optimizer.step()\n",
        "\n",
        "            with torch.no_grad(): # evaluate validation loss here \n",
        "\n",
        "                model.eval()\n",
        "                val_loss_epochs = []\n",
        "\n",
        "                for (inputval, labelval) in val_iterator:\n",
        "                    \n",
        "                    inputval = inputval.to(device)\n",
        "                    labelval = labelval.to(device)\n",
        "                    outval = model(inputval)\n",
        "                    lossval = criterion(outval, labelval.unsqueeze(-1)) # Calculate validation loss \n",
        "                    val_loss_epochs.append(lossval.item())\n",
        "\n",
        "                val_loss_epoch = np.mean(val_loss_epochs)\n",
        "                val_loss.append(round(val_loss_epoch, 3))\n",
        "\n",
        "            print('epoch: %d loss: %.3f val loss: %.3f' % (epoch + 1, loss.item(), val_loss_epoch))\n",
        "\n",
        "            '''# evalutate whether validation loss is dropping; if not, stop\n",
        "            if epoch > 21:\n",
        "                if val_loss[-1] >= np.min(val_loss[:-20]): \n",
        "                    print('Finished training at epoch {0}'.format(epoch))\n",
        "                    return epoch'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Thl2qBTdn4-"
      },
      "outputs": [],
      "source": [
        "model = regressionHead(kernel=3)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss= torch.nn.SmoothL1Loss()\n",
        "epochs = 500\n",
        "train_LLMRegresor(train_loader, val_loader, model, device, loss, opt, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO4nSCgbdn4-"
      },
      "outputs": [],
      "source": [
        "test_set, test_labels = test_loader.dataset.tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhlfExNqdn4_"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "test_set = test_set.to(dtype=torch.float32, device=device)\n",
        "test_labels = test_labels.to(dtype=torch.float32, device=device) \n",
        "outcome = model(test_set)\n",
        "\n",
        "print(outcome, test_labels)\n",
        "#import pdb; pdb.set_trace()\n",
        "\n",
        "x = np.array( list(range(0, len(outcome))) )\n",
        "y= torch.abs(outcome.squeeze(1)-test_labels).detach().cpu().numpy()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar( x, y )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outcome.squeeze(1)[1000:1300])\n",
        "print(test_labels[1000:1300])"
      ],
      "metadata": {
        "id": "Nim9nSg_8xuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test = loss(outcome, test_labels.unsqueeze(-1))\n",
        "print('MSE: ' + str(loss_test))\n",
        "print('RMSE: ' + str(torch.sqrt(loss_test)))"
      ],
      "metadata": {
        "id": "UuP5V3A6z1Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvO3qiBGdn4_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1mseO1-5eNd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "'''sequence_Example = \"A E T C Z A O\"\n",
        "sequence_Example = re.sub(r\"[UZOB]\", \"X\", sequence_Example)\n",
        "encoded_input = tokenizer(sequence_Example, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "print(output)'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "latent_msaprot_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b87ecdd70764b2f9a2d21230926b863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faa5eba9598e4a90b7f261b10bcfe847",
              "IPY_MODEL_c3c929b7eef9456a842197f4c0f64c02",
              "IPY_MODEL_45ffb5134b264edebce27e6f1fb935ab"
            ],
            "layout": "IPY_MODEL_615fdcd32f98425fae864e9fb800bd81"
          }
        },
        "faa5eba9598e4a90b7f261b10bcfe847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_373dfbeeed6f47c5aec62023234e5a71",
            "placeholder": "​",
            "style": "IPY_MODEL_2dcd698c77a94eb39f8b130661295d86",
            "value": " 89%"
          }
        },
        "c3c929b7eef9456a842197f4c0f64c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_657188850552479d87728d479780697f",
            "max": 22335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cac6f51421ff420a9d8ddf87d065a470",
            "value": 19829
          }
        },
        "45ffb5134b264edebce27e6f1fb935ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19c3aa9a55524159b829e288e3da74ee",
            "placeholder": "​",
            "style": "IPY_MODEL_393355f492bf421fa447a10ca09635d1",
            "value": " 19829/22335 [1:46:39&lt;18:29,  2.26it/s]"
          }
        },
        "615fdcd32f98425fae864e9fb800bd81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373dfbeeed6f47c5aec62023234e5a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dcd698c77a94eb39f8b130661295d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "657188850552479d87728d479780697f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac6f51421ff420a9d8ddf87d065a470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19c3aa9a55524159b829e288e3da74ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393355f492bf421fa447a10ca09635d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}